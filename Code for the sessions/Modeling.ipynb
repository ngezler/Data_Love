{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Machine Learning Models\n",
    "\n",
    "At this point, you should have cleaned and prepared data. ready to ingested by the algorithms you selected and to build your model.\n",
    "\n",
    "let's get started with importing the libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_prepared.csv')\n",
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use first the Holdout method where we split the data set into training set and test set.  \n",
    "A common split would be 80% / 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.80, test_size=0.20, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will build multiple models, lets define a function to avoid repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(model):\n",
    "    classifier = model()\n",
    "    classifier.fit(train_X, train_y)\n",
    "    print(classifier.score(test_X, test_y,))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7653631284916201\n"
     ]
    }
   ],
   "source": [
    "knc =classifier(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "svc = classifier(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the slides, Cross Validation allows us to use all of our data for training and testing, where the data is split into K folds and we use one of the folds as a test subset while training the data on the rest of the folds.  \n",
    "\n",
    "Lets define another function, and add one more argument for the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_cv(model, metric):\n",
    "    classifier = model()\n",
    "    scores = cross_validate(classifier, X, y, cv=10, scoring=metric)\n",
    "    print(scores['test_score'])\n",
    "    print(\"Average: \", scores['test_score'].mean())\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.79775281 0.74157303 0.83146067 0.85393258 0.80898876\n",
      " 0.83146067 0.83146067 0.87640449 0.78651685]\n",
      "Average:  0.802621722846442\n"
     ]
    }
   ],
   "source": [
    "knc_cv =classifier_cv(KNeighborsClassifier,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56097561 0.73529412 0.72       0.73170732 0.81818182 0.81481481\n",
      " 0.82758621 0.85185185 0.87096774 0.80769231]\n",
      "Average:  0.7739071785849155\n"
     ]
    }
   ],
   "source": [
    "knc_cv =classifier_cv(KNeighborsClassifier,'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83333333 0.79775281 0.7752809  0.85393258 0.80898876 0.78651685\n",
      " 0.78651685 0.79775281 0.86516854 0.7752809 ]\n",
      "Average:  0.8080524344569288\n"
     ]
    }
   ],
   "source": [
    "svc_cv = classifier_cv(SVC,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91666667 0.83333333 0.79166667 0.81818182 0.77419355 0.77777778\n",
      " 0.8        0.83333333 0.92307692 0.77777778]\n",
      "Average:  0.8246007845201394\n"
     ]
    }
   ],
   "source": [
    "svc_cv = classifier_cv(SVC,'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred=svc_cv.predict(X_test_set)\n",
    "# y_test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
